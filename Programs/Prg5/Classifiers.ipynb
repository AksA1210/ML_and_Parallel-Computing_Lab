{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qcbwBKB74nE",
        "outputId": "9c79d54f-d3c5-4426-e174-6211cb11618d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Loading the data\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "classifier = DecisionTreeClassifier()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "confusion_mx = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy :\", accuracy)\n",
        "print(\"Precision :\", precision)\n",
        "print(\"Recall :\", recall)\n",
        "print(\"F1 Score :\", f1)\n",
        "print(\"Confusion Matrix :\")\n",
        "print(confusion_mx)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "# Loading the data\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "classifier = RandomForestClassifier()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "confusion_mx = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy :\", accuracy)\n",
        "print(\"Precision :\", precision)\n",
        "print(\"Recall :\", recall)\n",
        "print(\"F1 Score :\", f1)\n",
        "print(\"Confusion Matrix :\")\n",
        "print(confusion_mx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSl_tTM38fkq",
        "outputId": "28a1dcd8-eaaf-4bec-867c-a0d81843aa81"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Loading data\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)\n",
        "\n",
        "# Train the classifier\n",
        "classifier = Perceptron()\n",
        "classifier.fit(X_train,y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "precision = precision_score(y_test,y_pred,average = \"weighted\")\n",
        "recall = recall_score(y_test,y_pred,average = \"weighted\")\n",
        "f1 = f1_score(y_test,y_pred,average = \"weighted\")\n",
        "confusion_mx = confusion_matrix(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy : \",accuracy)\n",
        "print(\"Precision : \",precision)\n",
        "print(\"Recall : \",recall)\n",
        "print(\"F1 Score : \",f1)\n",
        "print(\"Confusion matrix : \")\n",
        "print(confusion_mx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Zsw_5X69BFE",
        "outputId": "2975e547-7583-428e-9cee-adb57b3c71b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.8\n",
            "Precision :  0.875\n",
            "Recall :  0.8\n",
            "F1 Score :  0.7730769230769231\n",
            "Confusion matrix : \n",
            "[[10  0  0]\n",
            " [ 6  3  0]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Loading the data\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)\n",
        "\n",
        "# Train the classifier\n",
        "classifier = SVC()\n",
        "classifier.fit(X_train,y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "precision = precision_score(y_test,y_pred,average = \"weighted\")\n",
        "recall = recall_score(y_test,y_pred,average = \"weighted\")\n",
        "f1 = f1_score(y_test,y_pred,average = \"weighted\")\n",
        "confusion_mx = confusion_matrix(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy : \",accuracy)\n",
        "print(\"Precision : \",precision)\n",
        "print(\"Recall : \",recall)\n",
        "print(\"F1 Score : \",f1)\n",
        "print(\"Confusion matrix : \")\n",
        "print(confusion_mx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDxQIbHDClB7",
        "outputId": "e81d10ee-a597-436f-f219-b41165bb835c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  1.0\n",
            "Precision :  1.0\n",
            "Recall :  1.0\n",
            "F1 Score :  1.0\n",
            "Confusion matrix : \n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score,confusion_matrix\n",
        "\n",
        "# Loading the data\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 42)\n",
        "\n",
        "# Train the classifier\n",
        "classifier = MLPClassifier()\n",
        "classifier.fit(X_train,y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "precision = precision_score(y_test,y_pred,average = \"weighted\")\n",
        "recall = recall_score(y_test,y_pred,average = \"weighted\")\n",
        "f1 = f1_score(y_test,y_pred,average = \"weighted\")\n",
        "confusion_mx = confusion_matrix(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy : \",accuracy)\n",
        "print(\"Precision : \",precision)\n",
        "print(\"Recall : \",recall)\n",
        "print(\"F1 Score : \",f1)\n",
        "print(\"Confusion matrix : \")\n",
        "print(confusion_mx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3WxDp3hDTjI",
        "outputId": "b0ffd3b6-1860-42bc-ded7-5f55fe748da4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  1.0\n",
            "Precision :  1.0\n",
            "Recall :  1.0\n",
            "F1 Score :  1.0\n",
            "Confusion matrix : \n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score,confusion_matrix\n",
        "\n",
        "# Loading the data\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 42)\n",
        "\n",
        "# Train the classifier\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train,y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "precision = precision_score(y_test,y_pred,average = \"weighted\")\n",
        "recall = recall_score(y_test,y_pred,average = \"weighted\")\n",
        "f1 = f1_score(y_test,y_pred,average = \"weighted\")\n",
        "confusion_mx = confusion_matrix(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy : \",accuracy)\n",
        "print(\"Precision : \",precision)\n",
        "print(\"Recall : \",recall)\n",
        "print(\"F1 Score : \",f1)\n",
        "print(\"Confusion matrix : \")\n",
        "print(confusion_mx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXkEa8NbGGx8",
        "outputId": "d53267fb-e11a-4aa4-8366-c1a18a00bbb9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  1.0\n",
            "Precision :  1.0\n",
            "Recall :  1.0\n",
            "F1 Score :  1.0\n",
            "Confusion matrix : \n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score,confusion_matrix\n",
        "\n",
        "\n",
        "# Loading the data\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 42)\n",
        "\n",
        "# Train the classifier\n",
        "classifier = QuadraticDiscriminantAnalysis()\n",
        "classifier.fit(X_train,y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "precision = precision_score(y_test,y_pred,average = \"weighted\")\n",
        "recall = recall_score(y_test,y_pred,average = \"weighted\")\n",
        "f1 = f1_score(y_test,y_pred,average = \"weighted\")\n",
        "confusion_mx = confusion_matrix(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy : \",accuracy)\n",
        "print(\"Precision : \",precision)\n",
        "print(\"Recall : \",recall)\n",
        "print(\"F1 Score : \",f1)\n",
        "print(\"Confusion matrix : \")\n",
        "print(confusion_mx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_EWdKofH_bc",
        "outputId": "5fb956bc-f00d-4ba7-de2e-06db2ac61298"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.9666666666666667\n",
            "Precision :  0.9694444444444444\n",
            "Recall :  0.9666666666666667\n",
            "F1 Score :  0.9664109121909632\n",
            "Confusion matrix : \n",
            "[[10  0  0]\n",
            " [ 0  8  1]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier"
      ],
      "metadata": {
        "id": "fcGj5B4AB3Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Loading the data\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base classifiers\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "random_forest = RandomForestClassifier()\n",
        "\n",
        "# 1. Bagging\n",
        "bagging_classifier = BaggingClassifier(estimator=decision_tree, n_estimators=10, random_state=42)\n",
        "bagging_classifier.fit(X_train, y_train)\n",
        "bagging_predictions = bagging_classifier.predict(X_test)\n",
        "bagging_accuracy = accuracy_score(y_test, bagging_predictions)\n",
        "print(\"Bagging Accuracy:\", bagging_accuracy)\n",
        "\n",
        "# 2. Boosting (AdaBoost)\n",
        "adaboost_classifier = AdaBoostClassifier(estimator=decision_tree, n_estimators=50, random_state=42)\n",
        "adaboost_classifier.fit(X_train, y_train)\n",
        "adaboost_predictions = adaboost_classifier.predict(X_test)\n",
        "adaboost_accuracy = accuracy_score(y_test, adaboost_predictions)\n",
        "print(\"AdaBoost Accuracy:\", adaboost_accuracy)\n",
        "\n",
        "# 3. Stacking\n",
        "stacking_classifier = StackingClassifier(estimators=[('decision_tree', decision_tree), ('random_forest', random_forest)], final_estimator=random_forest)\n",
        "stacking_classifier.fit(X_train, y_train)\n",
        "stacking_predictions = stacking_classifier.predict(X_test)\n",
        "stacking_accuracy = accuracy_score(y_test, stacking_predictions)\n",
        "print(\"Stacking Accuracy:\", stacking_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHVTWbfgHljt",
        "outputId": "60a6b326-ae7b-4124-93c8-8d99852175fc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Accuracy: 1.0\n",
            "AdaBoost Accuracy: 1.0\n",
            "Stacking Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Loading the data\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base classifiers\n",
        "svm = SVC()\n",
        "random_forest = RandomForestClassifier()\n",
        "\n",
        "\n",
        "bagging_classifier = BaggingClassifier(estimator=svm, n_estimators=10, random_state=42)\n",
        "bagging_classifier.fit(X_train, y_train)\n",
        "bagging_predictions = bagging_classifier.predict(X_test)\n",
        "bagging_accuracy = accuracy_score(y_test, bagging_predictions)\n",
        "print(\"Bagging Accuracy :\", bagging_accuracy)\n",
        "\n",
        "\n",
        "adaboost_classifier = AdaBoostClassifier(estimator=svm, n_estimators=50, random_state=42)\n",
        "adaboost_classifier.fit(X_train, y_train)\n",
        "adaboost_predictions = adaboost_classifier.predict(X_test)\n",
        "adaboost_accuracy = accuracy_score(y_test, adaboost_predictions)\n",
        "print(\"AdaBoost Accuracy : \", adaboost_accuracy)\n",
        "\n",
        "\n",
        "stacking_classifier = StackingClassifier(estimators=[('svm', svm), ('random_forest', random_forest)], final_estimator=random_forest)\n",
        "stacking_classifier.fit(X_train, y_train)\n",
        "stacking_predictions = stacking_classifier.predict(X_test)\n",
        "stacking_accuracy = accuracy_score(y_test, stacking_predictions)\n",
        "print(\"Stacking Accuracy :\", stacking_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "Q5Cvm7_hJHlV",
        "outputId": "afe6b78a-2ca4-4b2e-8d6c-62e8db0c4df9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Accuracy : 1.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\nPlease change the base estimator or set algorithm='SAMME' instead.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-fc29457531a8>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# 2. Boosting (AdaBoost)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0madaboost_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0madaboost_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0madaboost_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madaboost_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0madaboost_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madaboost_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Check parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# Clear any previous fit results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_validate_estimator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SAMME.R\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predict_proba\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m    518\u001b[0m                     \u001b[0;34m\"AdaBoostClassifier with algorithm='SAMME.R' requires \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m                     \u001b[0;34m\"that the weak learner supports the calculation of class \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\nPlease change the base estimator or set algorithm='SAMME' instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load data\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base classifiers\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "mlp_classifier = MLPClassifier()\n",
        "\n",
        "bagging_classifier = BaggingClassifier(estimator=decision_tree, n_estimators=10, random_state=42)\n",
        "bagging_classifier.fit(X_train, y_train)\n",
        "bagging_predictions = bagging_classifier.predict(X_test)\n",
        "bagging_accuracy = accuracy_score(y_test, bagging_predictions)\n",
        "print(\"Bagging Accuracy:\", bagging_accuracy)\n",
        "\n",
        "adaboost_classifier = AdaBoostClassifier(estimator=decision_tree, n_estimators=50, random_state=42)\n",
        "adaboost_classifier.fit(X_train, y_train)\n",
        "adaboost_predictions = adaboost_classifier.predict(X_test)\n",
        "adaboost_accuracy = accuracy_score(y_test, adaboost_predictions)\n",
        "print(\"AdaBoost Accuracy:\", adaboost_accuracy)\n",
        "\n",
        "stacking_classifier = StackingClassifier(estimators=[('decision_tree', decision_tree), ('mlp_classifier', mlp_classifier)])\n",
        "stacking_classifier.fit(X_train, y_train)\n",
        "stacking_predictions = stacking_classifier.predict(X_test)\n",
        "stacking_accuracy = accuracy_score(y_test, stacking_predictions)\n",
        "print(\"Stacking Accuracy:\", stacking_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7hxK9gTJnzf",
        "outputId": "ca9f9295-12e8-4669-ff71-52c1e13cdafb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Accuracy: 1.0\n",
            "AdaBoost Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, StackingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Loading the data\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base classifiers\n",
        "MLP = MLPClassifier()\n",
        "random_forest = RandomForestClassifier()\n",
        "\n",
        "bagging_classifier = BaggingClassifier(estimator=MLP, n_estimators=10, random_state=42)\n",
        "bagging_classifier.fit(X_train, y_train)\n",
        "bagging_predictions = bagging_classifier.predict(X_test)\n",
        "bagging_accuracy = accuracy_score(y_test, bagging_predictions)\n",
        "print(\"Bagging Accuracy :\", bagging_accuracy)\n",
        "\n",
        "adaboost_classifier = AdaBoostClassifier(estimator=MLP, n_estimators=50, random_state=42)\n",
        "adaboost_classifier.fit(X_train, y_train)\n",
        "adaboost_predictions = adaboost_classifier.predict(X_test)\n",
        "adaboost_accuracy = accuracy_score(y_test, adaboost_predictions)\n",
        "print(\"AdaBoost Accuracy : \", adaboost_accuracy)\n",
        "\n",
        "stacking_classifier = StackingClassifier(estimators=[('MLP', MLP), ('random_forest', random_forest)], final_estimator=random_forest)\n",
        "stacking_classifier.fit(X_train, y_train)\n",
        "stacking_predictions = stacking_classifier.predict(X_test)\n",
        "stacking_accuracy = accuracy_score(y_test, stacking_predictions)\n",
        "print(\"Stacking Accuracy :\", stacking_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "0a0453c8-9e3a-4e21-8705-abe47c6a8a4d",
        "id": "f4XzpdV5KtRy"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Accuracy : 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "MLPClassifier doesn't support sample_weight.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-7b7291f6e07d>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# 2. Boosting (AdaBoost)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0madaboost_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMLP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0madaboost_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0madaboost_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madaboost_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0madaboost_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madaboost_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Check parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# Clear any previous fit results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_validate_estimator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 )\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_fit_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sample_weight\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    526\u001b[0m                 \u001b[0;34mf\"{self.estimator.__class__.__name__} doesn't support sample_weight.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: MLPClassifier doesn't support sample_weight."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yJbptBCQLd42"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}